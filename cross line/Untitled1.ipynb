{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find convolution of 2 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMask(mask_path):\n",
    "    # path to mask image\n",
    "    mask = cv2.imread(mask_path,0)\n",
    "    mask_position=set()\n",
    "    for row, value in enumerate(mask):\n",
    "        for column, element in enumerate(value):\n",
    "            if element == 255:\n",
    "                mask_position.add((column,row))\n",
    "    return mask_position\n",
    "\n",
    "def getBbox(bbox):\n",
    "    x,y,x_plus_w,y_plus_h = bbox \n",
    "    vehicle_position = itertools.product(range(x,x_plus_w+1),range(y,y_plus_h+1))\n",
    "    return set(vehicle_position)\n",
    "\n",
    "def getProbability2Shape(vehicle, mask):\n",
    "    match = len(vehicle)-len(vehicle.difference(mask))\n",
    "    bbox  = len(vehicle)\n",
    "    return (match*100)/bbox\n",
    "\n",
    "'''\n",
    "Just a mark for myself\n",
    "'''\n",
    "def get_output_layers(net):\n",
    "    '''\n",
    "    get all output layer names: with yolov3 is yolo_82, 94 and 106\n",
    "    ''' \n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidences, x, y, x_plus_w, y_plus_h):\n",
    "    '''\n",
    "    draw a bounding box around object\n",
    "    '''\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "    \n",
    "#     print(x,y,x_plus_w,y_plus_h)\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def bounding_pic(net, image, scale, size,mask):\n",
    "    '''\n",
    "    net: the model reading by open-cv (maybe YoLo or SSD)\n",
    "    image: image need to bouding box\n",
    "    scale: image pixel multiply with this\n",
    "    size: a tuple contain size of image\n",
    "    '''\n",
    "    Width = image.shape[1]\n",
    "    Height = image.shape[0]\n",
    "    # Resize picture to 416x416, because YOLO take in 416x416\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "    # set input is resized picture\n",
    "    net.setInput(blob)\n",
    "    # last layer of Yolo model\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.6\n",
    "    # maybe our model will detect many bouding box for an object, this threshold help us take the box with equal \n",
    "    #            or higher propability\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    '''\n",
    "    out is a 2D tensor like (number_of_objects, score_of_each_classes), with first five element in each row is special, \n",
    "    take e.g: out[0] = temp:\n",
    "        + temp[0]: x_center of that object\n",
    "        + temp[1]: y_center of that object\n",
    "        + temp[2]: width of that object\n",
    "        + temp[3]: height of that object\n",
    "        + temp[4]: unknow value\n",
    "        + from 5 to above is the score of that object to each classes => COCO have 80 class so each row contain 85 element,\n",
    "            will be 15 with CIFAR,and 1005 with IMAGENET  \n",
    "    '''\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            # get the highest score to determine its label\n",
    "            class_id = np.argmax(scores)\n",
    "            if class_id not in [0,1,2,3,7]:\n",
    "                continue\n",
    "            else:\n",
    "                # score of that object, make sure more than 50% correct label\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    # scale again with w and h\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    # remember it return x_center and y_center, not x,y, so we need to find x,y\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "    # detect bouding box around objects\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    # set the counting line\n",
    "    lineThickness = 2\n",
    "    \n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        x = round(box[0])\n",
    "        y = round(box[1])\n",
    "        w = round(box[2])\n",
    "        h = round(box[3])\n",
    "        draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "        bbox = getBbox((x,y,x+w,y+h))\n",
    "        conv = getProbability2Shape(bbox,mask)\n",
    "        text1 = 'Convolution: ' + str(round(conv,2)) + '%'\n",
    "        text2 = 'True' if conv > 80 else 'False'\n",
    "        cv2.putText(image, text1, (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "        cv2.putText(image, 'Fault: '+text2, (x, y+30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'YOLOv3-416\\\\yolov3.cfg'\n",
    "name = 'coco.names'\n",
    "weight = 'YOLOv3-416\\\\yolov3.weights'\n",
    "mask_path = './cross line/mask.jpg'\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(name, 'r') as f:\n",
    "    # generate all classes of COCO, bicycle ind = 1, car ind = 2 and motorbike ind = 3\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Read the model\n",
    "net = cv2.dnn.readNet(weight, config)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "# take shape of image in order to scale it to 416x416, first layer of Yolo CNN\n",
    "\n",
    "scale = 0.00392\n",
    "\n",
    "cap = cv2.VideoCapture('Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi')\n",
    "'''\n",
    "If output is not None\n",
    "'''\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "outputVideo = cv2.VideoWriter('C:/Users/ADMINS/Desktop/areaResult.avi', fourcc, 20, (1920,1080))\n",
    "\n",
    "#close\n",
    "\n",
    "frameNo = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "# for session_0_center\n",
    "mask = getMask(mask_path)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    thresh = 1\n",
    "    frameNo += 1\n",
    "\n",
    "    if count%thresh==0:\n",
    "        # Our operations on the frame come here\n",
    "        img = bounding_pic(net, frame, scale, (416,416),mask)\n",
    "        #510,496 1200,471 1527,616 706,749\n",
    "        img = cv2.line(img, (510,496), (1200,471), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1200,471), (1527,616), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1527,616), (706,749), (255,0,0), 3)\n",
    "        img = cv2.line(img, (706,749), (510,496), (255,0,0), 3)\n",
    "        cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('image', 800,600)\n",
    "        cv2.imshow('image',img)\n",
    "        outputVideo.write(frame)\n",
    "    \n",
    "    count += 1\n",
    "    if count == thresh*30:\n",
    "        count = 0\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "outputVideo.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the position of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distanceFromPoint2Line(p, line):\n",
    "    a,b,c = line[0],line[1],line[2]\n",
    "    try:\n",
    "        # if list or np.array shape 1\n",
    "        x,y = p[0],p[1]\n",
    "    except:\n",
    "        # if np.array shape 2\n",
    "        x,y = p[0][0], p[0][1]\n",
    "    finally:\n",
    "        top = abs(a*x+b*y+c)\n",
    "        bottom = np.linalg.norm(np.array([a,b]))\n",
    "        return top/bottom\n",
    "\n",
    "def cosineVetorPhase(v1,v2):\n",
    "    dotProduct = np.dot(v1,v2)\n",
    "    normV1 = np.linalg.norm(v1)\n",
    "    normV2 = np.linalg.norm(v2)\n",
    "    return dotProduct/(normV1*normV2)\n",
    "\n",
    "def checkSameSideNormalVector(p, line):\n",
    "    # p is numpy array with shape [1,3] with the final element is 1\n",
    "    # line is something like ax+by+c = 0, line =[a,b,c]\n",
    "    return (line[0]*p[0]+line[1]*p[1]+c) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ADMINS\\Anaconda3\\envs\\yolo\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from yolo import *\n",
    "from tracking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *\n",
    "from utils import *\n",
    "from vehicle import *\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "import os\n",
    "import utilities\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def bbox2necess(image, bbox,frame,shape):\n",
    "    \"\"\"\n",
    "    return a list, each element is a list contain [posX,posY,ID,frame_no, image bbox]\n",
    "    \"\"\"\n",
    "    final_res=[]\n",
    "    width = shape[0]\n",
    "    height = shape[1]\n",
    "    for box in bbox:\n",
    "        x = (box[0]/416)*width\n",
    "        y = (box[1]/416)*height\n",
    "        w = ((box[2]-box[0])/416)*width\n",
    "        h = ((box[3]-box[1])/416)*height\n",
    "        x_plus_w = x+w\n",
    "        y_plus_h = y+h\n",
    "        bbox2d = image[int(round(x)):int(round(x_plus_w)),int(round(y)):int(round(y_plus_h))]\n",
    "        x_centroid = x + w/2\n",
    "        y_centroid = y + h/2\n",
    "        res=[x_centroid,y_centroid,(box[4]),frame,bbox2d]\n",
    "        final_res.append(res)\n",
    "    return final_res\n",
    "\n",
    "\n",
    "def detect_video(yolo, video_type, video_path, output_path, \n",
    "                    scale, vp1, vp2, pp, allow_speed, allow_lanes,\n",
    "                    all_lanes, thresh_frame):\n",
    "    '''\n",
    "    - Input:\n",
    "        + yolo: yolo model\n",
    "        + video_type: 'local' when use video in PC and 'stream' for....stream\n",
    "        + video_path: path of video\n",
    "        + output_path: write down if u wanna something more clearly\n",
    "    - Output:\n",
    "        + A tensor [x,y,ID,frame_num]\n",
    "    '''\n",
    "    # these thing should append into data file\n",
    "    tuple_cam = computeCameraCalibration(vp1,vp2,pp)\n",
    "    \n",
    "\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    if video_type == 'stream':\n",
    "        fps = vid.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "    elif video_type == 'local':\n",
    "        fps = vid.get(7)\n",
    "    video_FourCC = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    isOutput = True if output_path != \"\" else False\n",
    "    if isOutput:\n",
    "        print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(fps), type(video_size))\n",
    "        out = cv2.VideoWriter(output_path, video_FourCC, fps, video_size)\n",
    "\n",
    "    tracker=Sort()\n",
    "    frame_num=0\n",
    "    all_vehicle={}\n",
    "    ignore_set = set()\n",
    "    while True:\n",
    "        return_value, pic = vid.read()\n",
    "        if not return_value:\n",
    "            break\n",
    "        image = Image.fromarray(pic)\n",
    "        if frame_num%thresh_frame==0:\n",
    "            if yolo.model_image_size != (None, None):\n",
    "                assert yolo.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "                assert yolo.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "                boxed_image = letterbox_image(image, tuple(reversed(yolo.model_image_size)))\n",
    "            else:\n",
    "                new_image_size = (image.width - (image.width % 32),\n",
    "                                image.height - (image.height % 32))\n",
    "                boxed_image = letterbox_image(image, new_image_size)\n",
    "            image_data = np.array(boxed_image, dtype='float32')\n",
    "            image_data /= 255.\n",
    "            image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "            \n",
    "            # detect for bbox right here\n",
    "\n",
    "            out_boxes, out_scores, out_classes = yolo.sess.run(\n",
    "                [yolo.boxes, yolo.scores, yolo.classes],\n",
    "                feed_dict={\n",
    "                    yolo.yolo_model.input: image_data,\n",
    "                    yolo.input_image_shape: [image.size[1], image.size[0]],\n",
    "                    K.learning_phase(): 0\n",
    "                })\n",
    "            final_box=[]\n",
    "            label=[]\n",
    "            scores=[]\n",
    "            for b,lb,sc in zip(out_boxes,out_classes,out_scores):\n",
    "                if lb in [2,3,5,7]:\n",
    "                    final_box.append(b)\n",
    "                    label.append(lb)\n",
    "                    scores.append(sc)\n",
    "\n",
    "            out_boxes=np.array(final_box)\n",
    "            out_classes=np.array(label)\n",
    "            out_scores=np.array(scores)\n",
    "            final_boxes=np.column_stack((out_boxes,out_scores))\n",
    "            final_boxes = final_boxes[np.logical_and(final_boxes[:, 4] > 0.3, final_boxes[:, 2] -\n",
    "                                                        final_boxes[:, 0] < 600)]\n",
    "\n",
    "                # Apply NMS\n",
    "            indices = utilities.non_max_suppression(final_boxes, 0.9, final_boxes[:, 4])\n",
    "            \n",
    "            out_boxes = [final_boxes[i] for i in indices]\n",
    "            out_classes= [out_classes[i] for i in indices]\n",
    "            rev=(reversed(out_classes))  # for display in order since yolo reverse the list \n",
    "            out_classes=[]\n",
    "            for r in rev:\n",
    "                out_classes.append(r)\n",
    "            out_classes=np.array(out_classes)\n",
    "            bf=out_boxes\n",
    "            res_track=tracker.update(np.array(out_boxes))\n",
    "            # res_track return [x,y, x+w, x+y, ID]\n",
    "            one_frame = bbox2necess(image = pic, bbox = res_track,frame =frame_num,\n",
    "                                        shape = video_size)\n",
    "            for vehicle in one_frame:\n",
    "                # [posX,posY,ID,frame_no, image bbox]\n",
    "                ID =  one_frame[2]\n",
    "                centroid = [one_frame[0],one_frame[1]]\n",
    "                frame_appear = one_frame[3]\n",
    "                bbox = one_frame[4]\n",
    "                \n",
    "                mode = 'speed'\n",
    "#                 if ID in ignore_set:\n",
    "#                     continue\n",
    "                if ID not in all_vehicle.keys():\n",
    "                    all_vehicle[ID] = Vehicle(ID, centroid, frame_appear, fps, scale,\n",
    "                                                tuple_cam, bbox, allow_speed, allow_lanes, \n",
    "                                                mode = mode)\n",
    "                else:\n",
    "                    all_vehicle[ID].update_for_highway(bbox, centroid, frame_appear)\n",
    "            frame_num+=1\n",
    "\n",
    "\n",
    "\n",
    "KalmanBoxTracker.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv3-416/yolo.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-00bac4c72bdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m a = detect_video(yolo = yolo, video_type = 'local', video_path = video_path, output_path = \"\", scale = scale,\n\u001b[0;32m     13\u001b[0m                 \u001b[0mvp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_speed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_lanes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallow_lanes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_lanes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_lanes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 thresh_frame = 10)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-af928aec172f>\u001b[0m in \u001b[0;36mdetect_video\u001b[1;34m(yolo, video_type, video_path, output_path, scale, vp1, vp2, pp, allow_speed, allow_lanes, all_lanes, thresh_frame)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;31m#                 if ID in ignore_set:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m#                     continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mID\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_vehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     all_vehicle[ID] = Vehicle(ID, centroid, frame_appear, fps, scale,\n\u001b[0;32m    142\u001b[0m                                                 \u001b[0mtuple_cam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_speed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_lanes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "video_path = 'Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi'\n",
    "yolo = Yolo(score = 0.3, iou = 0.45)\n",
    "vp1 = [144.737, 34.7794]\n",
    "vp2 = [12183.582175112755, 615.451021479187]\n",
    "pp = [960.5, 540.5]\n",
    "scale = 0.01822590999670784\n",
    "all_lanes = [np.array([ -0.92226493,   0.38655841, 130.89136422]),\n",
    "             np.array([-0.78325241,  0.62170384, 97.52101372]),\n",
    "             np.array([-0.65281474,  0.7575176 , 71.40300615]), \n",
    "             np.array([  0.57,  -1.  , -47.39])]\n",
    "allow_lanes = [1,2]\n",
    "a = detect_video(yolo = yolo, video_type = 'local', video_path = video_path, output_path = \"\", scale = scale,\n",
    "                vp1 = vp1, vp2 = vp2, pp = pp, allow_speed = 40, allow_lanes = allow_lanes, all_lanes = all_lanes,\n",
    "                thresh_frame = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "b = np.random.randint(1,10,(10,10,3))\n",
    "c = b[1:5,2:5]\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(np.float64(1.0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
