{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find convolution of 2 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMask(mask_path):\n",
    "    # path to mask image\n",
    "    mask = cv2.imread(mask_path,0)\n",
    "    mask_position=set()\n",
    "    for row, value in enumerate(mask):\n",
    "        for column, element in enumerate(value):\n",
    "            if element == 255:\n",
    "                mask_position.add((column,row))\n",
    "    return mask_position\n",
    "\n",
    "def getBbox(bbox):\n",
    "    x,y,x_plus_w,y_plus_h = bbox \n",
    "    vehicle_position = itertools.product(range(x,x_plus_w+1),range(y,y_plus_h+1))\n",
    "    return set(vehicle_position)\n",
    "\n",
    "def getProbability2Shape(vehicle, mask):\n",
    "    match = len(vehicle)-len(vehicle.difference(mask))\n",
    "    bbox  = len(vehicle)\n",
    "    return (match*100)/bbox\n",
    "\n",
    "'''\n",
    "Just a mark for myself\n",
    "'''\n",
    "def get_output_layers(net):\n",
    "    '''\n",
    "    get all output layer names: with yolov3 is yolo_82, 94 and 106\n",
    "    ''' \n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidences, x, y, x_plus_w, y_plus_h):\n",
    "    '''\n",
    "    draw a bounding box around object\n",
    "    '''\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "    \n",
    "#     print(x,y,x_plus_w,y_plus_h)\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def bounding_pic(net, image, scale, size,mask):\n",
    "    '''\n",
    "    net: the model reading by open-cv (maybe YoLo or SSD)\n",
    "    image: image need to bouding box\n",
    "    scale: image pixel multiply with this\n",
    "    size: a tuple contain size of image\n",
    "    '''\n",
    "    Width = image.shape[1]\n",
    "    Height = image.shape[0]\n",
    "    # Resize picture to 416x416, because YOLO take in 416x416\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "    # set input is resized picture\n",
    "    net.setInput(blob)\n",
    "    # last layer of Yolo model\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.6\n",
    "    # maybe our model will detect many bouding box for an object, this threshold help us take the box with equal \n",
    "    #            or higher propability\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    '''\n",
    "    out is a 2D tensor like (number_of_objects, score_of_each_classes), with first five element in each row is special, \n",
    "    take e.g: out[0] = temp:\n",
    "        + temp[0]: x_center of that object\n",
    "        + temp[1]: y_center of that object\n",
    "        + temp[2]: width of that object\n",
    "        + temp[3]: height of that object\n",
    "        + temp[4]: unknow value\n",
    "        + from 5 to above is the score of that object to each classes => COCO have 80 class so each row contain 85 element,\n",
    "            will be 15 with CIFAR,and 1005 with IMAGENET  \n",
    "    '''\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            # get the highest score to determine its label\n",
    "            class_id = np.argmax(scores)\n",
    "            if class_id not in [0,1,2,3,7]:\n",
    "                continue\n",
    "            else:\n",
    "                # score of that object, make sure more than 50% correct label\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    # scale again with w and h\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    # remember it return x_center and y_center, not x,y, so we need to find x,y\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "    # detect bouding box around objects\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    # set the counting line\n",
    "    lineThickness = 2\n",
    "    \n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        x = round(box[0])\n",
    "        y = round(box[1])\n",
    "        w = round(box[2])\n",
    "        h = round(box[3])\n",
    "        draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "        bbox = getBbox((x,y,x+w,y+h))\n",
    "        conv = getProbability2Shape(bbox,mask)\n",
    "        text1 = 'Convolution: ' + str(round(conv,2)) + '%'\n",
    "        text2 = 'True' if conv > 80 else 'False'\n",
    "        cv2.putText(image, text1, (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "        cv2.putText(image, 'Fault: '+text2, (x, y+30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'YOLOv3-416\\\\yolov3.cfg'\n",
    "name = 'coco.names'\n",
    "weight = 'YOLOv3-416\\\\yolov3.weights'\n",
    "mask_path = './cross line/mask.jpg'\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(name, 'r') as f:\n",
    "    # generate all classes of COCO, bicycle ind = 1, car ind = 2 and motorbike ind = 3\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Read the model\n",
    "net = cv2.dnn.readNet(weight, config)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "# take shape of image in order to scale it to 416x416, first layer of Yolo CNN\n",
    "\n",
    "scale = 0.00392\n",
    "\n",
    "cap = cv2.VideoCapture('Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi')\n",
    "'''\n",
    "If output is not None\n",
    "'''\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "outputVideo = cv2.VideoWriter('C:/Users/ADMINS/Desktop/areaResult.avi', fourcc, 20, (1920,1080))\n",
    "\n",
    "#close\n",
    "\n",
    "frameNo = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "# for session_0_center\n",
    "mask = getMask(mask_path)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    thresh = 1\n",
    "    frameNo += 1\n",
    "\n",
    "    if count%thresh==0:\n",
    "        # Our operations on the frame come here\n",
    "        img = bounding_pic(net, frame, scale, (416,416),mask)\n",
    "        #510,496 1200,471 1527,616 706,749\n",
    "        img = cv2.line(img, (510,496), (1200,471), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1200,471), (1527,616), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1527,616), (706,749), (255,0,0), 3)\n",
    "        img = cv2.line(img, (706,749), (510,496), (255,0,0), 3)\n",
    "        cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('image', 800,600)\n",
    "        cv2.imshow('image',img)\n",
    "        outputVideo.write(frame)\n",
    "    \n",
    "    count += 1\n",
    "    if count == thresh*30:\n",
    "        count = 0\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "outputVideo.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the position of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distanceFromPoint2Line(p, line):\n",
    "    a,b,c = line[0],line[1],line[2]\n",
    "    try:\n",
    "        # if list or np.array shape 1\n",
    "        x,y = p[0],p[1]\n",
    "    except:\n",
    "        # if np.array shape 2\n",
    "        x,y = p[0][0], p[0][1]\n",
    "    finally:\n",
    "        top = abs(a*x+b*y+c)\n",
    "        bottom = np.linalg.norm(np.array([a,b]))\n",
    "        return top/bottom\n",
    "\n",
    "def cosineVetorPhase(v1,v2):\n",
    "    dotProduct = np.dot(v1,v2)\n",
    "    normV1 = np.linalg.norm(v1)\n",
    "    normV2 = np.linalg.norm(v2)\n",
    "    return dotProduct/(normV1*normV2)\n",
    "\n",
    "def checkSameSideNormalVector(p, line):\n",
    "    # p is numpy array with shape [1,3] with the final element is 1\n",
    "    # line is something like ax+by+c = 0, line =[a,b,c]\n",
    "    return (line[0]*p[0]+line[1]*p[1]+c) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"YOLO_v3 Model Defined in Keras.\"\"\"\n",
    "\n",
    "from functools import wraps\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from utils import compose\n",
    "\n",
    "\n",
    "@wraps(Conv2D)\n",
    "def DarknetConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
    "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides')==(2,2) else 'same'\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
    "    x = DarknetConv2D_BN_Leaky(num_filters, (3,3), strides=(2,2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "                DarknetConv2D_BN_Leaky(num_filters//2, (1,1)),\n",
    "                DarknetConv2D_BN_Leaky(num_filters, (3,3)))(x)\n",
    "        x = Add()([x,y])\n",
    "    return x\n",
    "\n",
    "def darknet_body(x):\n",
    "    '''Darknent body having 52 Convolution2D layers'''\n",
    "    x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)))(x)\n",
    "    y = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D(out_filters, (1,1)))(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V3 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body(inputs))\n",
    "    x, y1 = make_last_layers(darknet.output, 512, num_anchors*(num_classes+5))\n",
    "\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(256, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x,darknet.layers[152].output])\n",
    "    x, y2 = make_last_layers(x, 256, num_anchors*(num_classes+5))\n",
    "\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(128, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x,darknet.layers[92].output])\n",
    "    x, y3 = make_last_layers(x, 128, num_anchors*(num_classes+5))\n",
    "\n",
    "    return Model(inputs, [y1,y2,y3])\n",
    "\n",
    "def tiny_yolo_body(inputs, num_anchors, num_classes):\n",
    "    '''Create Tiny YOLO_v3 model CNN body in keras.'''\n",
    "    x1 = compose(\n",
    "            DarknetConv2D_BN_Leaky(16, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(32, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(64, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(128, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(256, (3,3)))(inputs)\n",
    "    x2 = compose(\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(512, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(1024, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(256, (1,1)))(x1)\n",
    "    y1 = compose(\n",
    "            DarknetConv2D_BN_Leaky(512, (3,3)),\n",
    "            DarknetConv2D(num_anchors*(num_classes+5), (1,1)))(x2)\n",
    "\n",
    "    x2 = compose(\n",
    "            DarknetConv2D_BN_Leaky(128, (1,1)),\n",
    "            UpSampling2D(2))(x2)\n",
    "    y2 = compose(\n",
    "            Concatenate(),\n",
    "            DarknetConv2D_BN_Leaky(256, (3,3)),\n",
    "            DarknetConv2D(num_anchors*(num_classes+5), (1,1)))([x2,x1])\n",
    "\n",
    "    return Model(inputs, [y1,y2])\n",
    "\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    '''Get corrected boxes'''\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
    "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
    "    new_shape = K.round(image_shape * K.min(input_shape/image_shape))\n",
    "    offset = (input_shape-new_shape)/2./input_shape\n",
    "    scale = input_shape/new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes =  K.concatenate([\n",
    "        box_mins[..., 0:1],  # y_min\n",
    "        box_mins[..., 1:2],  # x_min\n",
    "        box_maxes[..., 0:1],  # y_max\n",
    "        box_maxes[..., 1:2]  # x_max\n",
    "    ])\n",
    "\n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes *= K.concatenate([image_shape, image_shape])\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n",
    "    '''Process Conv layer output'''\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats,\n",
    "        anchors, num_classes, input_shape)\n",
    "    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = K.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = K.reshape(box_scores, [-1, num_classes])\n",
    "    return boxes, box_scores\n",
    "\n",
    "\n",
    "def yolo_eval(yolo_outputs,\n",
    "              anchors,\n",
    "              num_classes,\n",
    "              image_shape,\n",
    "              max_boxes=20,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n",
    "    num_layers = len(yolo_outputs)\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]] # default setting\n",
    "    input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    for l in range(num_layers):\n",
    "        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l],\n",
    "            anchors[anchor_mask[l]], num_classes, input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = K.concatenate(boxes, axis=0)\n",
    "    box_scores = K.concatenate(box_scores, axis=0)\n",
    "\n",
    "    mask = box_scores >= score_threshold\n",
    "    max_boxes_tensor = K.constant(max_boxes, dtype='int32')\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(num_classes):\n",
    "        # TODO: use keras backend instead of tf.\n",
    "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
    "        nms_index = tf.image.non_max_suppression(\n",
    "            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "        class_boxes = K.gather(class_boxes, nms_index)\n",
    "        class_box_scores = K.gather(class_box_scores, nms_index)\n",
    "        classes = K.ones_like(class_box_scores, 'int32') * c\n",
    "        boxes_.append(class_boxes)\n",
    "        scores_.append(class_box_scores)\n",
    "        classes_.append(classes)\n",
    "    boxes_ = K.concatenate(boxes_, axis=0)\n",
    "    scores_ = K.concatenate(scores_, axis=0)\n",
    "    classes_ = K.concatenate(classes_, axis=0)\n",
    "\n",
    "    return boxes_, scores_, classes_\n",
    "\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    '''Preprocess true boxes to training input format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes: array, shape=(m, T, 5)\n",
    "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
    "    input_shape: array-like, hw, multiples of 32\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
    "\n",
    "    '''\n",
    "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh)==0: continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],\n",
    "             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = K.control_flow_ops.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "        if print_loss:\n",
    "            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)], message='loss: ')\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from timeit import default_timer as timer\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import tensorflow\n",
    "import colorsys\n",
    "import os\n",
    "import utilities\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Yolo(object):\n",
    "#     from sort import Sort\n",
    "    _defaults = {\n",
    "        \"model_path\": 'YOLOv3-416/yolo.h5',\n",
    "        \"anchors_path\": 'YOLOv3-416/yolo_anchors.txt',\n",
    "        \"classes_path\": 'YOLOv3-416/coco.names',\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"gpu_num\" : 1,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    def __init__(self, score, iou, **kwargs):\n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.score = score\n",
    "        self.iou   = iou\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "#         self.tracker=Sort()\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if self.gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *\n",
    "from utils import *\n",
    "\n",
    "import cv2\n",
    "def detect_video(yolo, video_path, output_path=\"\"):\n",
    "    '''\n",
    "    detect and give ID for each object\n",
    "    => working on this def\n",
    "    '''\n",
    "    \n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    video_FourCC = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_fps       = vid.get(cv2.CAP_PROP_FPS)\n",
    "    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    isOutput = True if output_path != \"\" else False\n",
    "    if isOutput:\n",
    "        print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(video_fps), type(video_size))\n",
    "        out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    tracker=Sort()\n",
    "    frame_num=0\n",
    "    result_track_all_frames=[]\n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        if not return_value:\n",
    "            break\n",
    "        image = Image.fromarray(frame)\n",
    "        if yolo.model_image_size != (None, None):\n",
    "            assert yolo.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert yolo.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(yolo.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "        \n",
    "        '''\n",
    "        detect for bbox right here\n",
    "        '''\n",
    "        out_boxes, out_scores, out_classes = yolo.sess.run(\n",
    "            [yolo.boxes, yolo.scores, yolo.classes],\n",
    "            feed_dict={\n",
    "                yolo.yolo_model.input: image_data,\n",
    "                yolo.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        final_box=[]\n",
    "        label=[]\n",
    "        scores=[]\n",
    "        for b,lb,sc in zip(out_boxes,out_classes,out_scores):\n",
    "            if lb in [2,3,5,7]:\n",
    "                final_box.append(b)\n",
    "                label.append(lb)\n",
    "                scores.append(sc)\n",
    "\n",
    "        out_boxes=np.array(final_box)\n",
    "        out_classes=np.array(label)\n",
    "        out_scores=np.array(scores)\n",
    "        final_boxes=np.column_stack((out_boxes,out_scores))\n",
    "        final_boxes = final_boxes[np.logical_and(final_boxes[:, 4] > 0.3, final_boxes[:, 2] -\n",
    "                                                     final_boxes[:, 0] < 600)]\n",
    "\n",
    "            # Apply NMS\n",
    "        indices = utilities.non_max_suppression(final_boxes, 0.9, final_boxes[:, 4])\n",
    "        \n",
    "        out_boxes = [final_boxes[i] for i in indices]\n",
    "        out_classes= [out_classes[i] for i in indices]\n",
    "        rev=(reversed(out_classes))  # for display in order since yolo reverse the list \n",
    "        out_classes=[]\n",
    "        for r in rev:\n",
    "            out_classes.append(r)\n",
    "        out_classes=np.array(out_classes)\n",
    "        bf=out_boxes\n",
    "        res_track=tracker.update(np.array(out_boxes))\n",
    "        print(res_track)\n",
    "        result_track_all_frames.append(convert_bbox(res_track,frame_num))\n",
    "        frame_num+=1\n",
    "        \n",
    "    return np.array(result_track_all_frames)\n",
    "\n",
    "KalmanBoxTracker.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_bbox(bbox,frame):\n",
    "    \"\"\"\n",
    "    Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "    \"\"\"\n",
    "    final_res=[]\n",
    "    for box in bbox:\n",
    "        res=[]\n",
    "        w = box[2]-box[0]\n",
    "        h = box[3]-box[1]\n",
    "        x = box[0]+w/2.\n",
    "        y = box[1]+h/2.\n",
    "        s = w*h    #scale is just area\n",
    "        r = w/float(h)\n",
    "        res=np.array([x,y,w,h,(box[4]),frame])\n",
    "        final_res.append(res)\n",
    "    return np.array(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv3-416/yolo.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111\n\t [[node conv2d_2_6/convolution (defined at C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3650) ]]\n\nCaused by op 'conv2d_2_6/convolution', defined at:\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-d12db785a922>\", line 2, in <module>\n    yolo = Yolo(score = 0.3, iou = 0.45)\n  File \"<ipython-input-9-5867527a1d83>\", line 40, in __init__\n    self.boxes, self.scores, self.classes = self.generate()\n  File \"<ipython-input-9-5867527a1d83>\", line 65, in generate\n    self.yolo_model = load_model(model_path, compile=False)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 419, in load_model\n    model = _deserialize_model(f, custom_objects, compile)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 225, in _deserialize_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 458, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\layers\\__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 145, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\", line 1032, in from_config\n    process_node(layer, node_data)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\", line 991, in process_node\n    layer(unpack_singleton(input_tensors), **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 171, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3650, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 851, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1025, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111\n\t [[node conv2d_2_6/convolution (defined at C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3650) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAbortedError\u001b[0m: Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111\n\t [[{{node conv2d_2_6/convolution}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d12db785a922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0myolo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYolo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myolo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-58d59fe6c70a>\u001b[0m in \u001b[0;36mdetect_video\u001b[1;34m(yolo, video_path, output_path)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_image_shape\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             })\n\u001b[0;32m     57\u001b[0m         \u001b[0mfinal_box\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAbortedError\u001b[0m: Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111\n\t [[node conv2d_2_6/convolution (defined at C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3650) ]]\n\nCaused by op 'conv2d_2_6/convolution', defined at:\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-d12db785a922>\", line 2, in <module>\n    yolo = Yolo(score = 0.3, iou = 0.45)\n  File \"<ipython-input-9-5867527a1d83>\", line 40, in __init__\n    self.boxes, self.scores, self.classes = self.generate()\n  File \"<ipython-input-9-5867527a1d83>\", line 65, in generate\n    self.yolo_model = load_model(model_path, compile=False)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 419, in load_model\n    model = _deserialize_model(f, custom_objects, compile)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 225, in _deserialize_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 458, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\layers\\__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 145, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\", line 1032, in from_config\n    process_node(layer, node_data)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\", line 991, in process_node\n    layer(unpack_singleton(input_tensors), **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 171, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3650, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 851, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1025, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111\n\t [[node conv2d_2_6/convolution (defined at C:\\Users\\ADMINS\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3650) ]]\n"
     ]
    }
   ],
   "source": [
    "video_path = 'Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi'\n",
    "yolo = Yolo(score = 0.3, iou = 0.45)\n",
    "a = detect_video(yolo, video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow \n",
    "print(tensorflow.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
