{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find convolution of 2 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMask(mask_path):\n",
    "    # path to mask image\n",
    "    mask = cv2.imread(mask_path,0)\n",
    "    mask_position=set()\n",
    "    for row, value in enumerate(mask):\n",
    "        for column, element in enumerate(value):\n",
    "            if element == 255:\n",
    "                mask_position.add((column,row))\n",
    "    return mask_position\n",
    "\n",
    "def getBbox(bbox):\n",
    "    x,y,x_plus_w,y_plus_h = bbox \n",
    "    vehicle_position = itertools.product(range(x,x_plus_w+1),range(y,y_plus_h+1))\n",
    "    return set(vehicle_position)\n",
    "\n",
    "def getProbability2Shape(vehicle, mask):\n",
    "    match = len(vehicle)-len(vehicle.difference(mask))\n",
    "    bbox  = len(vehicle)\n",
    "    return (match*100)/bbox\n",
    "\n",
    "'''\n",
    "Just a mark for myself\n",
    "'''\n",
    "def get_output_layers(net):\n",
    "    '''\n",
    "    get all output layer names: with yolov3 is yolo_82, 94 and 106\n",
    "    ''' \n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidences, x, y, x_plus_w, y_plus_h):\n",
    "    '''\n",
    "    draw a bounding box around object\n",
    "    '''\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "    \n",
    "#     print(x,y,x_plus_w,y_plus_h)\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def bounding_pic(net, image, scale, size,mask):\n",
    "    '''\n",
    "    net: the model reading by open-cv (maybe YoLo or SSD)\n",
    "    image: image need to bouding box\n",
    "    scale: image pixel multiply with this\n",
    "    size: a tuple contain size of image\n",
    "    '''\n",
    "    Width = image.shape[1]\n",
    "    Height = image.shape[0]\n",
    "    # Resize picture to 416x416, because YOLO take in 416x416\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "    # set input is resized picture\n",
    "    net.setInput(blob)\n",
    "    # last layer of Yolo model\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.6\n",
    "    # maybe our model will detect many bouding box for an object, this threshold help us take the box with equal \n",
    "    #            or higher propability\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    '''\n",
    "    out is a 2D tensor like (number_of_objects, score_of_each_classes), with first five element in each row is special, \n",
    "    take e.g: out[0] = temp:\n",
    "        + temp[0]: x_center of that object\n",
    "        + temp[1]: y_center of that object\n",
    "        + temp[2]: width of that object\n",
    "        + temp[3]: height of that object\n",
    "        + temp[4]: unknow value\n",
    "        + from 5 to above is the score of that object to each classes => COCO have 80 class so each row contain 85 element,\n",
    "            will be 15 with CIFAR,and 1005 with IMAGENET  \n",
    "    '''\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            # get the highest score to determine its label\n",
    "            class_id = np.argmax(scores)\n",
    "            if class_id not in [0,1,2,3,7]:\n",
    "                continue\n",
    "            else:\n",
    "                # score of that object, make sure more than 50% correct label\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    # scale again with w and h\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    # remember it return x_center and y_center, not x,y, so we need to find x,y\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "    # detect bouding box around objects\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    # set the counting line\n",
    "    lineThickness = 2\n",
    "    \n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        x = round(box[0])\n",
    "        y = round(box[1])\n",
    "        w = round(box[2])\n",
    "        h = round(box[3])\n",
    "        draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "        bbox = getBbox((x,y,x+w,y+h))\n",
    "        conv = getProbability2Shape(bbox,mask)\n",
    "        text1 = 'Convolution: ' + str(round(conv,2)) + '%'\n",
    "        text2 = 'True' if conv > 80 else 'False'\n",
    "        cv2.putText(image, text1, (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "        cv2.putText(image, 'Fault: '+text2, (x, y+30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'YOLOv3-416\\\\yolov3.cfg'\n",
    "name = 'coco.names'\n",
    "weight = 'YOLOv3-416\\\\yolov3.weights'\n",
    "mask_path = './cross line/mask.jpg'\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(name, 'r') as f:\n",
    "    # generate all classes of COCO, bicycle ind = 1, car ind = 2 and motorbike ind = 3\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Read the model\n",
    "net = cv2.dnn.readNet(weight, config)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "# take shape of image in order to scale it to 416x416, first layer of Yolo CNN\n",
    "\n",
    "scale = 0.00392\n",
    "\n",
    "cap = cv2.VideoCapture('Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi')\n",
    "'''\n",
    "If output is not None\n",
    "'''\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "outputVideo = cv2.VideoWriter('C:/Users/ADMINS/Desktop/areaResult.avi', fourcc, 20, (1920,1080))\n",
    "\n",
    "#close\n",
    "\n",
    "frameNo = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "# for session_0_center\n",
    "mask = getMask(mask_path)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    thresh = 1\n",
    "    frameNo += 1\n",
    "\n",
    "    if count%thresh==0:\n",
    "        # Our operations on the frame come here\n",
    "        img = bounding_pic(net, frame, scale, (416,416),mask)\n",
    "        #510,496 1200,471 1527,616 706,749\n",
    "        img = cv2.line(img, (510,496), (1200,471), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1200,471), (1527,616), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1527,616), (706,749), (255,0,0), 3)\n",
    "        img = cv2.line(img, (706,749), (510,496), (255,0,0), 3)\n",
    "        cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('image', 800,600)\n",
    "        cv2.imshow('image',img)\n",
    "        outputVideo.write(frame)\n",
    "    \n",
    "    count += 1\n",
    "    if count == thresh*30:\n",
    "        count = 0\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "outputVideo.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the position of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distanceFromPoint2Line(p, line):\n",
    "    a,b,c = line[0],line[1],line[2]\n",
    "    try:\n",
    "        # if list or np.array shape 1\n",
    "        x,y = p[0],p[1]\n",
    "    except:\n",
    "        # if np.array shape 2\n",
    "        x,y = p[0][0], p[0][1]\n",
    "    finally:\n",
    "        top = abs(a*x+b*y+c)\n",
    "        bottom = np.linalg.norm(np.array([a,b]))\n",
    "        return top/bottom\n",
    "\n",
    "def cosineVetorPhase(v1,v2):\n",
    "    dotProduct = np.dot(v1,v2)\n",
    "    normV1 = np.linalg.norm(v1)\n",
    "    normV2 = np.linalg.norm(v2)\n",
    "    return dotProduct/(normV1*normV2)\n",
    "\n",
    "def checkSameSideNormalVector(p, line):\n",
    "    # p is numpy array with shape [1,3] with the final element is 1\n",
    "    # line is something like ax+by+c = 0, line =[a,b,c]\n",
    "    return (line[0]*p[0]+line[1]*p[1]+c) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from timeit import default_timer as timer\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import tensorflow\n",
    "import colorsys\n",
    "import os\n",
    "import utilities\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class YOLO(object):\n",
    "#     from sort import Sort\n",
    "    _defaults = {\n",
    "        \"model_path\": 'model_data/yolo.h5',\n",
    "        \"anchors_path\": 'model_data/yolo_anchors.txt',\n",
    "        \"classes_path\": 'model_data/coco_classes.txt',\n",
    "        \"score\" : 0.3,\n",
    "        \"iou\" : 0.45,\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"gpu_num\" : 1,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "#         self.tracker=Sort()\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if self.gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *\n",
    "\n",
    "import cv2\n",
    "def detect_video(yolo, video_path, output_path=\"\"):\n",
    "    '''\n",
    "    detect and give ID for each object\n",
    "    => working on this def\n",
    "    '''\n",
    "    \n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    video_FourCC = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_fps       = vid.get(cv2.CAP_PROP_FPS)\n",
    "    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    isOutput = True if output_path != \"\" else False\n",
    "    if isOutput:\n",
    "        print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(video_fps), type(video_size))\n",
    "        out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    tracker=Sort()\n",
    "    frame_num=0\n",
    "    result_track_all_frames=[]\n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        if not return_value:\n",
    "            break\n",
    "        image = Image.fromarray(frame)\n",
    "        if yolo.model_image_size != (None, None):\n",
    "            assert yolo.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert yolo.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(yolo.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "        \n",
    "        '''\n",
    "        detect for bbox right here\n",
    "        '''\n",
    "        out_boxes, out_scores, out_classes = yolo.sess.run(\n",
    "            [yolo.boxes, yolo.scores, yolo.classes],\n",
    "            feed_dict={\n",
    "                yolo.yolo_model.input: image_data,\n",
    "                yolo.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        final_box=[]\n",
    "        label=[]\n",
    "        scores=[]\n",
    "        for b,lb,sc in zip(out_boxes,out_classes,out_scores):\n",
    "            if lb in [2,3,5,7]:\n",
    "                final_box.append(b)\n",
    "                label.append(lb)\n",
    "                scores.append(sc)\n",
    "\n",
    "        out_boxes=np.array(final_box)\n",
    "        out_classes=np.array(label)\n",
    "        out_scores=np.array(scores)\n",
    "        final_boxes=np.column_stack((out_boxes,out_scores))\n",
    "        final_boxes = final_boxes[np.logical_and(final_boxes[:, 4] > 0.3, final_boxes[:, 2] -\n",
    "                                                     final_boxes[:, 0] < 600)]\n",
    "\n",
    "            # Apply NMS\n",
    "        indices = utilities.non_max_suppression(final_boxes, 0.9, final_boxes[:, 4])\n",
    "        \n",
    "        out_boxes = [final_boxes[i] for i in indices]\n",
    "        out_classes= [out_classes[i] for i in indices]\n",
    "        rev=(reversed(out_classes))  # for display in order since yolo reverse the list \n",
    "        out_classes=[]\n",
    "        for r in rev:\n",
    "            out_classes.append(r)\n",
    "        out_classes=np.array(out_classes)\n",
    "        bf=out_boxes\n",
    "        res_track=tracker.update(np.array(out_boxes))\n",
    "        result_track_all_frames.append(convert_bbox(res_track,frame_num))\n",
    "        frame_num+=1\n",
    "        \n",
    "    return np.array(result_track_all_frames)\n",
    "\n",
    "KalmanBoxTracker.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_bbox(bbox,frame):\n",
    "    \"\"\"\n",
    "    Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "    \"\"\"\n",
    "    final_res=[]\n",
    "    for box in bbox:\n",
    "        res=[]\n",
    "        w = box[2]-box[0]\n",
    "        h = box[3]-box[1]\n",
    "        x = box[0]+w/2.\n",
    "        y = box[1]+h/2.\n",
    "        s = w*h    #scale is just area\n",
    "        r = w/float(h)\n",
    "        res=np.array([x,y,w,h,(box[4]),frame])\n",
    "        final_res.append(res)\n",
    "    return np.array(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_data/coco_classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f42623f222f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Z:/Vehicle speed measuring/video_speed measure/front.avi'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myolo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-2a055a0b98b9>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_defaults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set up default values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# and update with user overrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-2a055a0b98b9>\u001b[0m in \u001b[0;36m_get_class\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mclasses_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_data/coco_classes.txt'"
     ]
    }
   ],
   "source": [
    "video_path = 'Z:/Vehicle speed measuring/video_speed measure/front.avi'\n",
    "yolo = YOLO()\n",
    "a = detect_video(video_path, yolo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
