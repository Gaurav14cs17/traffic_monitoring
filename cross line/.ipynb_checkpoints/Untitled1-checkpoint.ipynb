{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find convolution of 2 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMask(mask_path):\n",
    "    # path to mask image\n",
    "    mask = cv2.imread(mask_path,0)\n",
    "    mask_position=set()\n",
    "    for row, value in enumerate(mask):\n",
    "        for column, element in enumerate(value):\n",
    "            if element == 255:\n",
    "                mask_position.add((column,row))\n",
    "    return mask_position\n",
    "\n",
    "def getBbox(bbox):\n",
    "    x,y,x_plus_w,y_plus_h = bbox \n",
    "    vehicle_position = itertools.product(range(x,x_plus_w+1),range(y,y_plus_h+1))\n",
    "    return set(vehicle_position)\n",
    "\n",
    "def getProbability2Shape(vehicle, mask):\n",
    "    match = len(vehicle)-len(vehicle.difference(mask))\n",
    "    bbox  = len(vehicle)\n",
    "    return (match*100)/bbox\n",
    "\n",
    "'''\n",
    "Just a mark for myself\n",
    "'''\n",
    "def get_output_layers(net):\n",
    "    '''\n",
    "    get all output layer names: with yolov3 is yolo_82, 94 and 106\n",
    "    ''' \n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidences, x, y, x_plus_w, y_plus_h):\n",
    "    '''\n",
    "    draw a bounding box around object\n",
    "    '''\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "    \n",
    "#     print(x,y,x_plus_w,y_plus_h)\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def bounding_pic(net, image, scale, size,mask):\n",
    "    '''\n",
    "    net: the model reading by open-cv (maybe YoLo or SSD)\n",
    "    image: image need to bouding box\n",
    "    scale: image pixel multiply with this\n",
    "    size: a tuple contain size of image\n",
    "    '''\n",
    "    Width = image.shape[1]\n",
    "    Height = image.shape[0]\n",
    "    # Resize picture to 416x416, because YOLO take in 416x416\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "    # set input is resized picture\n",
    "    net.setInput(blob)\n",
    "    # last layer of Yolo model\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.6\n",
    "    # maybe our model will detect many bouding box for an object, this threshold help us take the box with equal \n",
    "    #            or higher propability\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    '''\n",
    "    out is a 2D tensor like (number_of_objects, score_of_each_classes), with first five element in each row is special, \n",
    "    take e.g: out[0] = temp:\n",
    "        + temp[0]: x_center of that object\n",
    "        + temp[1]: y_center of that object\n",
    "        + temp[2]: width of that object\n",
    "        + temp[3]: height of that object\n",
    "        + temp[4]: unknow value\n",
    "        + from 5 to above is the score of that object to each classes => COCO have 80 class so each row contain 85 element,\n",
    "            will be 15 with CIFAR,and 1005 with IMAGENET  \n",
    "    '''\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            # get the highest score to determine its label\n",
    "            class_id = np.argmax(scores)\n",
    "            if class_id not in [0,1,2,3,7]:\n",
    "                continue\n",
    "            else:\n",
    "                # score of that object, make sure more than 50% correct label\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    # scale again with w and h\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    # remember it return x_center and y_center, not x,y, so we need to find x,y\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "    # detect bouding box around objects\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    # set the counting line\n",
    "    lineThickness = 2\n",
    "    \n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        x = round(box[0])\n",
    "        y = round(box[1])\n",
    "        w = round(box[2])\n",
    "        h = round(box[3])\n",
    "        draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "        bbox = getBbox((x,y,x+w,y+h))\n",
    "        conv = getProbability2Shape(bbox,mask)\n",
    "        text1 = 'Convolution: ' + str(round(conv,2)) + '%'\n",
    "        text2 = 'True' if conv > 80 else 'False'\n",
    "        cv2.putText(image, text1, (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "        cv2.putText(image, 'Fault: '+text2, (x, y+30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'YOLOv3-416\\\\yolov3.cfg'\n",
    "name = 'YOLOv3-416\\\\coco.names'\n",
    "weight = 'YOLOv3-416\\\\yolov3.weights'\n",
    "mask_path = './cross line/mask.jpg'\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(name, 'r') as f:\n",
    "    # generate all classes of COCO, bicycle ind = 1, car ind = 2 and motorbike ind = 3\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Read the model\n",
    "net = cv2.dnn.readNet(weight, config)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "# take shape of image in order to scale it to 416x416, first layer of Yolo CNN\n",
    "\n",
    "scale = 0.00392\n",
    "\n",
    "cap = cv2.VideoCapture('Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi')\n",
    "'''\n",
    "If output is not None\n",
    "'''\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "outputVideo = cv2.VideoWriter('C:/Users/ADMINS/Desktop/areaResult.avi', fourcc, 20, (1920,1080))\n",
    "\n",
    "#close\n",
    "\n",
    "frameNo = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "# for session_0_center\n",
    "mask = getMask(mask_path)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    thresh = 1\n",
    "    frameNo += 1\n",
    "\n",
    "    if count%thresh==0:\n",
    "        # Our operations on the frame come here\n",
    "        img = bounding_pic(net, frame, scale, (416,416),mask)\n",
    "        #510,496 1200,471 1527,616 706,749\n",
    "        img = cv2.line(img, (510,496), (1200,471), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1200,471), (1527,616), (255,0,0), 3)\n",
    "        img = cv2.line(img, (1527,616), (706,749), (255,0,0), 3)\n",
    "        img = cv2.line(img, (706,749), (510,496), (255,0,0), 3)\n",
    "        cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('image', 800,600)\n",
    "        cv2.imshow('image',img)\n",
    "        outputVideo.write(frame)\n",
    "    \n",
    "    count += 1\n",
    "    if count == thresh*30:\n",
    "        count = 0\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "outputVideo.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the position of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distanceFromPoint2Line(p, line):\n",
    "    a,b,c = line[0],line[1],line[2]\n",
    "    try:\n",
    "        # if list or np.array shape 1\n",
    "        x,y = p[0],p[1]\n",
    "    except:\n",
    "        # if np.array shape 2\n",
    "        x,y = p[0][0], p[0][1]\n",
    "    finally:\n",
    "        top = abs(a*x+b*y+c)\n",
    "        bottom = np.linalg.norm(np.array([a,b]))\n",
    "        return top/bottom\n",
    "\n",
    "def cosineVetorPhase(v1,v2):\n",
    "    dotProduct = np.dot(v1,v2)\n",
    "    normV1 = np.linalg.norm(v1)\n",
    "    normV2 = np.linalg.norm(v2)\n",
    "    return dotProduct/(normV1*normV2)\n",
    "\n",
    "def checkSameSideNormalVector(p, line):\n",
    "    # p is numpy array with shape [1,3] with the final element is 1\n",
    "    # line is something like ax+by+c = 0, line =[a,b,c]\n",
    "    return (line[0]*p[0]+line[1]*p[1]+c) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from timeit import default_timer as timer\n",
    "from keras.utils import multi_gpu_model\n",
    "from  yolo_loading import *\n",
    "\n",
    "import tensorflow.compat.v1 as tensorflow\n",
    "import colorsys\n",
    "import os\n",
    "import utilities\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Yolo(object):\n",
    "#     from sort import Sort\n",
    "    _defaults = {\n",
    "        \"model_path\": 'YOLOv3-416/yolo.h5',\n",
    "        \"anchors_path\": 'YOLOv3-416/yolo_anchors.txt',\n",
    "        \"classes_path\": 'YOLOv3-416/coco.names',\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"gpu_num\" : 1,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    def __init__(self, score, iou, **kwargs):\n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.score = score\n",
    "        self.iou   = iou\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "#         self.tracker=Sort()\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if self.gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug for cross red line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def getMask(mask_path):\n",
    "    # path to mask image\n",
    "    mask = cv2.imread(mask_path,0)\n",
    "    mask_position=set()\n",
    "    for row, value in enumerate(mask):\n",
    "        for column, element in enumerate(value):\n",
    "            if element == 255:\n",
    "                mask_position.add((column,row))\n",
    "    return mask_position\n",
    "\n",
    "def getBbox(bbox):\n",
    "    x,y,x_plus_w,y_plus_h = bbox \n",
    "    vehicle_position = itertools.product(range(x,x_plus_w+1),range(y,y_plus_h+1))\n",
    "    return set(vehicle_position)\n",
    "\n",
    "def getProbability2Shape(vehicle, mask):\n",
    "    match = len(vehicle)-len(vehicle.difference(mask))\n",
    "    bbox  = len(vehicle)\n",
    "    return (match*100)/bbox\n",
    "\n",
    "def distanceFromPoint2Line(p, line):\n",
    "    a,b,c = line[0],line[1],line[2]\n",
    "    try:\n",
    "        # if list or np.array shape 1\n",
    "        x,y = p[0],p[1]\n",
    "    except:\n",
    "        # if np.array shape 2\n",
    "        x,y = p[0][0], p[0][1]\n",
    "    finally:\n",
    "        top = abs(a*x+b*y+c)\n",
    "        bottom = np.linalg.norm(np.array([a,b]))\n",
    "        return top/bottom\n",
    "\n",
    "def cosineVectorPhase(v1,v2):\n",
    "    dotProduct = np.dot(v1,v2)\n",
    "    normV1 = np.linalg.norm(v1)\n",
    "    normV2 = np.linalg.norm(v2)\n",
    "    return dotProduct/(normV1*normV2)\n",
    "\n",
    "def checkSameSideNormalVector(p, line):\n",
    "    # p is numpy array with shape [1,3] with the final element is 1\n",
    "    # line is something like ax+by+c = 0, line =[a,b,c]\n",
    "    return (line[0]*p[0]+line[1]*p[1]+line[2]) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "need to fix:\n",
    " + change cross lane permission into parameter.\n",
    " + set time disappear to clean up while running, for higher speed and for rtsp.\n",
    " + cross red line, deadline 28/10/2019.\n",
    " + build a basic model to recognize color in traffic light area.\n",
    "finish:\n",
    " + debug for speed.\n",
    " + debug for fps.\n",
    " + debug for saving path of fault vehicle.\n",
    " + debug for cross Lane.\n",
    " + devide 2 part for this class, private update for each situation.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from vehicle_speed import *\n",
    "from cross_red_line import *\n",
    "\n",
    "class Vehicle:\n",
    "    def __init__(self, ID, centroid, frame_appear,  bbox, \n",
    "                     allow_lanes, all_lanes, **kwags):\n",
    "        '''\n",
    "        watch ignore list in tracking\n",
    "        tuple_cam include vp1,vp2, vp3, pp, roadPlane, focal (put this into main)\n",
    "        calculate speed, measure lane, cross line if fault, save bbox into directionary\n",
    "        delete vehicle in N time disappear\n",
    "        check if thresh car problem in 1 time -> traffic jam\n",
    "        # fix to have bbox in main #\n",
    "        '''\n",
    "        '''\n",
    "        for cross_line:\n",
    "            accept_line\n",
    "            right_ditection = False\n",
    "            area of interest\n",
    "            \n",
    "        '''\n",
    "        #### need another network to regconize the license plate for both speed and\n",
    "        #### cross red line (especially this)\n",
    "        self.ID = ID\n",
    "        self.centroids = [centroid, None]\n",
    "        self.frame = [frame_appear, None]\n",
    "        self.bbox  = bbox # image\n",
    "        self.lane = getLaneForPoint(centroid,all_lanes)\n",
    "\n",
    "        # this thing\n",
    "        self._catch_cross_lane = False\n",
    "        \n",
    "        \n",
    "        self.allow_lanes = allow_lanes\n",
    "        self.all_lanes = all_lanes\n",
    "        \n",
    "        # this part 's belong to **kwags, should not change it\n",
    "        self._called = 0\n",
    "        # Use for save the speed of fault car\n",
    "        self.mode = 'speed'\n",
    "        self._overSpeed_path = './OverSpeed/'\n",
    "        self._crossLane_path = './CrossLane/'\n",
    "        self._crossRedLine_path = './crossRedLine/'\n",
    "        self._problem_path = './carWithProblem/'\n",
    "        self._crossLane = False\n",
    "        self._problem   = False\n",
    "\n",
    "        if self._catch_cross_lane and (self.lane not in self.allow_lanes) and not self._crossLane:\n",
    "            self.catch_fault_vehicle(self._crossLane_path)\n",
    "            self._crossLane = True\n",
    "\n",
    "    def setParemeter4speedMeasure(self, fps, scale, tuple_cam, allow_speed, \n",
    "                                    best_performance_line):\n",
    "        # set parameter if mode is speed\n",
    "        self.speed = 0\n",
    "        self.fps = fps\n",
    "        self.scale = scale\n",
    "        self.allow_speed = allow_speed\n",
    "        self.speed_avarage = []\n",
    "        self.tuple_cam = tuple_cam\n",
    "        self.best_performance_line = best_performance_line\n",
    "        self._overSpeed = False\n",
    "\n",
    "        \n",
    "    def update_for_highway(self, new_bbox, new_centroid, new_frame):\n",
    "        # update all element and calculate speed, instead of all the other fault\n",
    "        # except cross line\n",
    "        # this function update in mode 'highway' in main, can measure speed and \n",
    "        # detect the vehicle with problem\n",
    "        # Assume that there will be no traffic jam on highway\n",
    "\n",
    "\n",
    "        vp1, vp2, vp3, pp, roadPlane, focal = self.tuple_cam\n",
    "        laneDivLines = self.all_lanes\n",
    "        self.centroids[1] = new_centroid\n",
    "        self.frame[1] = new_frame\n",
    "        self.bbox = new_bbox\n",
    "        self.lane = getLaneForPoint(new_centroid, laneDivLines)\n",
    "\n",
    "        self._called += 1\n",
    "        time_appear = self._called/self.fps\n",
    "        \n",
    "        # On highway, which car appears more than 20 second and doesn't move\n",
    "        # => gets in trouble\n",
    "        if time_appear >= 20 and np.average(np.array(self.speed)) <= 5 and not self._problem:\n",
    "            self._problem = True\n",
    "            self.catch_fault_vehicle(self._problem_path)\n",
    "\n",
    "        # On highway, lane is count from left to right, start at 1, only catch \n",
    "        # fault if this road is not allow to cross lane.\n",
    "        if self._catch_cross_lane and (self.lane not in self.allow_lanes) and not self._crossLane:\n",
    "            self.catch_fault_vehicle(self._crossLane_path)\n",
    "            self._crossLane = True\n",
    "\n",
    "        # Make sure car in the area with best camera calibration for best measurement\n",
    "        # take avarage speed for problem car\n",
    "        ### lack of counting time to clean up whenever a car disappear for 3s\n",
    "        if  (not(getLaneForPoint(self.centroids[0], laneDivLines) is None or \\\n",
    "               getLaneForPoint(self.centroids[1], laneDivLines) is None)) \\\n",
    "               and new_centroid[0]>= self.best_performance_line:\n",
    "            frame_diff = self.frame[1]-self.frame[0]\n",
    "            \n",
    "            self.speed = calculateSpeeds(self.centroids[0],self.centroids[1], self.fps, \n",
    "                                self.scale, frame_diff, self.tuple_cam)\n",
    "            self.speed_avarage.append(self.speed)\n",
    "\n",
    "            if (self.speed > self.allow_speed) and not self._overSpeed :\n",
    "                self.catch_fault_vehicle(self._overSpeed_path)\n",
    "                self._overSpeed = True\n",
    "        self.centroids[0] = new_centroid\n",
    "        self.frame[0] = new_frame\n",
    "\n",
    "    def setParemeter4crossRedLine(self, deadline, traffic_status, areaOfInterest):\n",
    "        self._crossRedLine = False\n",
    "        self._right_direction = False\n",
    "        self.deadline = deadline\n",
    "        self.traffic_status = traffic_status\n",
    "        self.areaOfInterest = areaOfInterest\n",
    "        \n",
    "        # rediculous\n",
    "\n",
    "        self.catched = \"Nope\"\n",
    "        \n",
    "\n",
    "    def update_for_cross_redline(self, new_centroid, frame_appear, traffic_status,\n",
    "                                 bbox2D_position):\n",
    "        self.centroids[1] = new_centroid\n",
    "        if distanceFromPoint2Line(new_centroid, self.deadline) <= 20:\n",
    "            v = np.array([self.centroids[1][0]-self.centroids[0][0], \\\n",
    "                        self.centroids[1][1]-self.centroids[0][0]])\n",
    "            n = np.array([self.deadline[0],self.deadline[1]])\n",
    "            cosine_phase = cosineVectorPhase(v,n)\n",
    "\n",
    "            if cosine_phase < 1 and cosine_phase > 0:\n",
    "                self._right_direction = True\n",
    "            \n",
    "            if self._right_direction and self.traffic_status == 'red'  \\\n",
    "                and checkSameSideNormalVector(new_centroid, self.deadline):\n",
    "                vehicle = getBbox(bbox2D_position)\n",
    "                prob = getProbability2Shape(vehicle, self.areaOfInterest)\n",
    "                print(prob)\n",
    "                if prob >= 80:\n",
    "                    self.catch_fault_vehicle(self._crossRedLine_path)\n",
    "\n",
    "                    self.catched = \"yeah\"\n",
    "\n",
    "        self.centroids[0]=new_centroid\n",
    "\n",
    "    def catch_fault_vehicle(self, src):\n",
    "        # mode: 'speed', 'other'\n",
    "        ID, frame, bbox , mode = self.ID, self.frame[-1], self.bbox, self.mode\n",
    "        if self.mode == 'speed':\n",
    "            cv2.imwrite(src + str(frame) + '_' + str(round(self.speed,2))+ \"_vehicle_\" + str(ID) + \".jpg\", bbox)\n",
    "        else:\n",
    "            cv2.imwrite(src+str(frame)+ \"_vehicle_\" + str(ID) + \".jpg\", bbox)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *\n",
    "from utils import *\n",
    "# from vehicle import *\n",
    "# from cross_red_line import *\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "import os\n",
    "import utilities\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def bbox2necess(image, bbox,frame,shape):\n",
    "    \"\"\"\n",
    "    return a list, each element is a list contain [posX,posY,ID,frame_no, image bbox]\n",
    "    \"\"\"\n",
    "    final_res=[]\n",
    "    width = shape[0]\n",
    "    height = shape[1]\n",
    "#     print(width,height)\n",
    "    for box in bbox:\n",
    "#         print(box)\n",
    "        x = int(round(box[0]))\n",
    "        y = int(round(box[1]))\n",
    "        w = int(round(box[2]-box[0]))\n",
    "        h = int(round(box[3]))-int(round(box[1]))\n",
    "#         print(x,y,w,h)\n",
    "        x_plus_w = x+w\n",
    "        y_plus_h = y+h\n",
    "        bbox2d = image[x:x_plus_w,y:y_plus_h]\n",
    "        x_centroid = x + w/2\n",
    "        y_centroid = y + h/2\n",
    "        bbox2d_position = [x ,y,x_plus_w,y_plus_h]\n",
    "        res=[x_centroid,y_centroid,(box[4]), frame, bbox2d, bbox2d_position]\n",
    "        final_res.append(res)\n",
    "    return final_res\n",
    "\n",
    "\n",
    "def detect_video(yolo, video_type, video_path, output_path, mask_path, mode, \n",
    "                    scale, vp1, vp2, pp, allow_speed, best_performance_line,\n",
    "                    deadline4Red, allow_lanes, all_lanes, thresh_frame):\n",
    "    '''\n",
    "    - Input:\n",
    "        + yolo: yolo model\n",
    "        + video_type: 'local' when use video in PC and 'stream' for....stream\n",
    "        + video_path: path of video\n",
    "        + output_path: write down if u wanna something more clearly\n",
    "    - Output:\n",
    "        + A tensor [x,y,ID,frame_num]\n",
    "    '''\n",
    "    # these thing should append into data file\n",
    "    tuple_cam = computeCameraCalibration(vp1,vp2,pp)\n",
    "    \n",
    "    # show for debug\n",
    "    \n",
    "#     cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "#     cv2.resizeWindow('image', 1000,600)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # require opencv 3.2\n",
    "    \n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    if video_type == 'stream':\n",
    "        fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "    elif video_type == 'local':\n",
    "        fps = vid.get(5)\n",
    "    # get(7) is all number of frame in video\n",
    "    # get(5) is get fps, fuck\n",
    "    \n",
    "    video_FourCC = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "#     print(video_size)\n",
    "    isOutput = True if output_path != \"\" else False\n",
    "    if isOutput:\n",
    "#         print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(fps), type(video_size))\n",
    "        out = cv2.VideoWriter(output_path, video_FourCC, fps, video_size, 1)\n",
    "\n",
    "    tracker=Sort()\n",
    "    frame_num=0\n",
    "    all_vehicle={}\n",
    "#     ignore_set = set()\n",
    "\n",
    "    mask = getMask(mask_path)\n",
    "    \n",
    "    while True:\n",
    "        return_value, pic = vid.read()\n",
    "        if not return_value:\n",
    "            break\n",
    "        image = Image.fromarray(pic)\n",
    "        if frame_num%thresh_frame==0:\n",
    "            if yolo.model_image_size != (None, None):\n",
    "                assert yolo.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "                assert yolo.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "                boxed_image = letterbox_image(image, tuple(reversed(yolo.model_image_size)))\n",
    "            else:\n",
    "                new_image_size = (image.width - (image.width % 32),\n",
    "                                image.height - (image.height % 32))\n",
    "                boxed_image = letterbox_image(image, new_image_size)\n",
    "            image_data = np.array(boxed_image, dtype='float32')\n",
    "            image_data /= 255.\n",
    "            image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "            \n",
    "            # detect for bbox right here\n",
    "\n",
    "            out_boxes, out_scores, out_classes = yolo.sess.run( \n",
    "                [yolo.boxes, yolo.scores, yolo.classes],  \n",
    "                feed_dict={\n",
    "                    yolo.yolo_model.input: image_data,\n",
    "                    yolo.input_image_shape: [image.size[1], image.size[0]],\n",
    "                    K.learning_phase(): 0\n",
    "                })\n",
    "            final_box=[]\n",
    "            label=[]\n",
    "            scores=[]\n",
    "            for b,lb,sc in zip(out_boxes,out_classes,out_scores):\n",
    "                if lb in [2,3,5,7]:\n",
    "                    final_box.append(b)\n",
    "                    label.append(lb)\n",
    "                    scores.append(sc)\n",
    "\n",
    "            out_boxes=np.array(final_box)\n",
    "            out_classes=np.array(label)\n",
    "            out_scores=np.array(scores)\n",
    "            final_boxes=np.column_stack((out_boxes,out_scores))\n",
    "            final_boxes = final_boxes[np.logical_and(final_boxes[:, 4] > 0.3, final_boxes[:, 2] -\n",
    "                                                        final_boxes[:, 0] < 600)]\n",
    "\n",
    "                # Apply NMS\n",
    "            indices = utilities.non_max_suppression(final_boxes, 0.9, final_boxes[:, 4])\n",
    "            \n",
    "            out_boxes = [final_boxes[i] for i in indices]\n",
    "            out_classes= [out_classes[i] for i in indices]\n",
    "            rev=(reversed(out_classes))  # for display in order since yolo reverse the list \n",
    "            out_classes=[]\n",
    "            for r in rev:\n",
    "                out_classes.append(r)\n",
    "            out_classes=np.array(out_classes)\n",
    "            bf=out_boxes\n",
    "            res_track=tracker.update(np.array(out_boxes))\n",
    "            # res_track return [x,y, x+w, x+y, ID]\n",
    "            one_frame = bbox2necess(image = pic, bbox = res_track,frame =frame_num,\n",
    "                                        shape = video_size)\n",
    "            for vehicle in one_frame:\n",
    "                ID =  int(round(vehicle[2]))\n",
    "                centroid = [vehicle[0],vehicle[1]]\n",
    "                frame_appear = frame_num\n",
    "                bbox = vehicle[4]\n",
    "                bbox2d_position = vehicle[5]\n",
    "\n",
    "                # for show video, will delete later\n",
    "                font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale              = 1\n",
    "                fontColor              = (0,0,255)\n",
    "                thickness              = 3\n",
    "                linetype               = cv2.LINE_AA\n",
    "                c_0 = int(round(centroid[0]))\n",
    "                c_1 = int(round(centroid[1]))\n",
    "                #end \n",
    "                traffic_status = 'red'\n",
    "\n",
    "                if ID not in all_vehicle.keys():\n",
    "                    all_vehicle[ID] = Vehicle(ID, centroid, frame_appear, bbox, allow_lanes, \n",
    "                                                all_lanes, mode = mode)\n",
    "                    if mode == 'speed':\n",
    "                        all_vehicle[ID].setParemeter4speedMeasure(fps, scale, tuple_cam,\n",
    "                                                            allow_speed, best_performance_line)\n",
    "                    elif mode == 'crossRedLine':\n",
    "                        all_vehicle[ID].setParemeter4crossRedLine(deadline = deadline4Red, \n",
    "                                            traffic_status = traffic_status,\n",
    "                                            areaOfInterest = mask)\n",
    "                    continue\n",
    "\n",
    "                if mode =='speed':\n",
    "                    all_vehicle[ID].update_for_highway(bbox, centroid, frame_appear)\n",
    "                    #show for debug\n",
    "                    \n",
    "                    cv2.putText(pic,str(ID), \n",
    "                                (c_1 - 10 , c_0 -10), \n",
    "                                font, \n",
    "                                fontScale,\n",
    "                                fontColor,\n",
    "                                thickness,\n",
    "                                linetype)\n",
    "                    cv2.putText(pic,str(all_vehicle[ID].speed), \n",
    "                                (c_1 -10 , c_0 +20), \n",
    "                                font, \n",
    "                                fontScale,\n",
    "                                fontColor,\n",
    "                                thickness,\n",
    "                                linetype)\n",
    "#                     out.write(pic)\n",
    "#                     cv2.imshow('image',pic)\n",
    "\n",
    "                elif mode == 'crossRedLine':\n",
    "                    cv2.putText(pic,str(ID), \n",
    "                                (c_1 - 10 , c_0 -10), \n",
    "                                font, \n",
    "                                fontScale,\n",
    "                                fontColor,\n",
    "                                thickness,\n",
    "                                linetype)\n",
    "                    cv2.putText(pic, all_vehicle[ID].catched, \n",
    "                                (c_1 - 10 , c_0 +20), \n",
    "                                font, \n",
    "                                fontScale,\n",
    "                                fontColor,\n",
    "                                thickness,\n",
    "                                linetype)\n",
    "#                     out.write(pic)\n",
    "#                     cv2.imshow('image',pic)\n",
    "                    \n",
    "                    all_vehicle[ID].update_for_cross_redline(centroid, frame_appear, \n",
    "                                    traffic_status, bbox2d_position)\n",
    "    \n",
    "\n",
    "#         if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#             break  \n",
    "        out.write(pic)\n",
    "#         print(frame_num)\n",
    "        frame_num+=1\n",
    "        \n",
    "    vid.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "KalmanBoxTracker.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'YOLOv3-416/yolo.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-afd22b0d5d8f>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'YOLOv3-416/yolo.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a4e8ef124539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0myolo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYolo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mvp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m144.737\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m34.7794\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mvp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m12183.582175112755\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m615.451021479187\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-afd22b0d5d8f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, score, iou, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;31m#         self.tracker=Sort()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-afd22b0d5d8f>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtiny_yolo_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_anchors\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_tiny_version\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0myolo_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_anchors\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# make sure model, anchors and classes match\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'YOLOv3-416/yolo.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "KalmanBoxTracker.count = 0\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "video_path = 'Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi'\n",
    "yolo = Yolo(score = 0.3, iou = 0.45)\n",
    "vp1 = [144.737, 34.7794]\n",
    "vp2 = [12183.582175112755, 615.451021479187]\n",
    "pp = [960, 540]\n",
    "scale = 0.01822590999670784\n",
    "all_lanes = [np.array([ -0.92226493,   0.38655841, 130.89136422]),\n",
    "             np.array([-0.78325241,  0.62170384, 97.52101372]),\n",
    "             np.array([-0.65281474,  0.7575176 , 71.40300615]), \n",
    "             np.array([  0.57,  -1.  , -47.39])]\n",
    "allow_lanes = [1,2]\n",
    "deadline = [0.041, 1, -518.585]\n",
    "a = detect_video(yolo = yolo, video_type = 'local', video_path = video_path, output_path = \"C:/Users/ADMINS/Desktop/tracking_red.avi\",\n",
    "                mask_path= 'mask.jpg', mode= 'crossRedLine', scale = scale,vp1 = vp1, vp2 = vp2, pp = pp, \n",
    "                allow_speed = 40, best_performance_line = 350, deadline4Red = deadline,\n",
    "                allow_lanes = allow_lanes, all_lanes = all_lanes,\n",
    "                thresh_frame = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "incompatible dimensions for cross product\n(dimension must be 2 or 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-526c2d543154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuple_cam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeCameraCalibration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvp2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroadPlane\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfocal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple_cam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprojector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgetWorldCoordinagesOnRoadPlane\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfocal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroadPlane\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-630eb85be5f3>\u001b[0m in \u001b[0;36mcomputeCameraCalibration\u001b[1;34m(_vp1, _vp2, _pp)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mvp2W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_vp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfocal\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mppW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mvp3W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvp1W\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mppW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvp2W\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mppW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mvp3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvp3W\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvp3W\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfocal\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mppW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mvp3Direction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvp3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfocal\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mppW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mcross\u001b[1;34m(a, b, axisa, axisb, axisc, axis)\u001b[0m\n\u001b[0;32m   1827\u001b[0m            \"(dimension must be 2 or 3)\")\n\u001b[0;32m   1828\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1829\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m     \u001b[1;31m# Create the output array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: incompatible dimensions for cross product\n(dimension must be 2 or 3)"
     ]
    }
   ],
   "source": [
    "tuple_cam = computeCameraCalibration(vp1,vp2,pp)\n",
    "vp1, vp2, vp3, pp, roadPlane, focal = tuple_cam\n",
    "projector = lambda p: getWorldCoordinagesOnRoadPlane(p, focal, roadPlane, pp)\n",
    "points = map(lambda x,y: np.array([x,y,1]), [5,6], [7,8])\n",
    "points = map(projector, points)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([5, 6, 1]), array([7, 8, 1])]\n"
     ]
    }
   ],
   "source": [
    "vp1 = [144.737, 34.7794]\n",
    "vp2 = [12183.582175112755, 615.451021479187]\n",
    "pp = [960.5, 540.5]\n",
    "vp1, vp2, vp3, pp, roadPlane, focal = tuple_cam\n",
    "points = map(lambda p: np.array([p[-2],p[-1],1]), ([5,6],[7,8]))\n",
    "print(list(points))\n",
    "# points = map(projector, points)\n",
    "\n",
    "# print(list(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First created\n",
      "First deleted\n",
      "1 Counter objects remaining\n"
     ]
    }
   ],
   "source": [
    "from weakref import WeakValueDictionary\n",
    "\n",
    "class Counter:\n",
    "    _instances = WeakValueDictionary()\n",
    "    @property\n",
    "    def Count(self):\n",
    "        return len(self._instances)\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self._instances[id(self)] = self\n",
    "        print (name, 'created')\n",
    "\n",
    "    def __del__(self):\n",
    "        print (self.name, 'deleted')\n",
    "        if self.Count == 0:\n",
    "            print ('Last Counter object deleted')\n",
    "        else:\n",
    "            print (self.Count, 'Counter objects remaining')\n",
    "\n",
    "x = Counter(\"First\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO line 215:22: Added keywords to args of function 'tf.boolean_mask'\n",
      "INFO line 216:27: Added keywords to args of function 'tf.boolean_mask'\n",
      "INFO line 389:23: Added keywords to args of function 'tf.boolean_mask'\n",
      "INFO line 411:19: Renamed 'tf.Print' to 'tf.compat.v1.Print'\n",
      "TensorFlow 2.0 Upgrade Script\n",
      "-----------------------------\n",
      "Converted 1 files\n",
      "Detected 0 issues that require attention\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Make sure to read the detailed log 'report.txt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-28 10:39:07.623482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"
     ]
    }
   ],
   "source": [
    "!tf_upgrade_v2 --infile yolo_loading.py --outfile yolo_loading-update.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "video_path = 'Z:\\\\Vehicle speed measuring\\\\video_speed measure\\\\front.avi'\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "# fourcc = cv2.CV_FOURCC('m', 'p', '4', 'v') # upper case - yl3\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "out = cv2.VideoWriter(\"C:/Users/ADMINS/Desktop/tracking.avi\", fourcc , 25, size, 1) #20.0: number of frames per sec\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "#         frame = cv2.flip(frame,1)\n",
    "\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
